<!DOCTYPE html>
<html  >
<head>
  <!-- Site made with Mobirise Website Builder v5.2.0, https://mobirise.com -->
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Mobirise v5.2.0, mobirise.com">
  <meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
  <link rel="shortcut icon" href="assets/images/logo5.png" type="image/x-icon">
  <meta name="description" content="">
  
  
  <title>Page 1</title>
  <link rel="stylesheet" href="assets/web/assets/mobirise-icons2/mobirise2.css">
  <link rel="stylesheet" href="assets/tether/tether.min.css">
  <link rel="stylesheet" href="assets/bootstrap/css/bootstrap.min.css">
  <link rel="stylesheet" href="assets/bootstrap/css/bootstrap-grid.min.css">
  <link rel="stylesheet" href="assets/bootstrap/css/bootstrap-reboot.min.css">
  <link rel="stylesheet" href="assets/theme/css/style.css">
  <link href="assets/fonts/style.css" rel="stylesheet">
  <link rel="preload" as="style" href="assets/mobirise/css/mbr-additional.css"><link rel="stylesheet" href="assets/mobirise/css/mbr-additional.css" type="text/css">
  
  
  
  
</head>
<body>
  
  <section class="slider1 cid-sg7w48l00x" id="slider1-n">
    
    <div class="carousel slide carousel-fade" id="sg9DSjA5W3" data-interval="5000">
        <ol class="carousel-indicators">
            <li data-slide-to="0" class="active" data-target="#sg9DSjA5W3"></li><li data-slide-to="1" class="active" data-target="#sg9DSjA5W3"></li>
            <li data-slide-to="2" data-target="#sg9DSjA5W3"></li><li data-slide-to="3" data-target="#sg9DSjA5W3"></li><li data-slide-to="4" data-target="#sg9DSjA5W3"></li>
            
        </ol>
        <div class="carousel-inner">
            <div class="carousel-item slider-image item active">
                <div class="item-wrapper">
                    <img class="d-block w-100" src="assets/images/slider1-1440x900.jpg" data-slide-to="0">
                    
                    
                </div>
            </div>
            <div class="carousel-item slider-image item">
                <div class="item-wrapper">
                    <img class="d-block w-100" src="assets/images/slider2-1440x900.jpg">
                    
                    
                </div>
            </div>
            <div class="carousel-item slider-image item">
                <div class="item-wrapper">
                    <img class="d-block w-100" src="assets/images/slider3-1440x900.jpg">
                    
                    
                </div>
            </div><div class="carousel-item slider-image item">
                <div class="item-wrapper">
                    <img class="d-block w-100" src="assets/images/frame-13-1440x900.png">
                    
                    
                </div>
            </div><div class="carousel-item slider-image item">
                <div class="item-wrapper">
                    <img class="d-block w-100" src="assets/images/frame-14-1-1440x900.png">
                    
                    
                </div>
            </div>
        </div>
        <a class="carousel-control carousel-control-prev" role="button" data-slide="prev" href="#sg9DSjA5W3">
            <span class="mobi-mbri mobi-mbri-arrow-prev" aria-hidden="true"></span>
            <span class="sr-only">Previous</span>
        </a>
        <a class="carousel-control carousel-control-next" role="button" data-slide="next" href="#sg9DSjA5W3">
            <span class="mobi-mbri mobi-mbri-arrow-next" aria-hidden="true"></span>
            <span class="sr-only">Next</span>
        </a>
    </div>
</section>

<section class="header10 cid-sg7MMljcQM" id="header10-o">

    

    

    <div class="align-center container-fluid">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9">
                <h1 class="mbr-section-title mbr-fonts-style mb-3 display-5"><strong><br></strong><strong>AS CSAM SURGES IN INDIA, </strong><br><strong>A NEW DRIVE TO PROSECUTE OFFENDERS</strong></h1>
                <p class="mbr-text mbr-fonts-style display-7">
                    STORY BY&nbsp;SHAMSHEER YOUSAF&nbsp;</p>
                
                <div class="image-wrap mt-4">
                    <img src="assets/images/kollam-1-700x533.png" alt="Mobirise" title="">
                </div>
            </div>
        </div>
    </div>
</section>

<section class="content15 cid-sg820DoJa1" id="content15-r">

    

    
    <div class="container">
        <div class="row justify-content-center">
            <div class="card col-md-12 col-lg-8">
                <div class="card-wrapper">
                    <div class="card-box align-left">
                        
                        <p class="mbr-text mbr-fonts-style display-7"><strong>Operation P-HUNT 20.1 </strong>ient port city of Kollam on June 27, the police team looked up at the passing clouds anxiously. “Not today, please,” was the common thought. It had rained all through Friday. Even during the 'before times' of the coronavirus pandemic, the monsoon was never a good time for any large outdoor operation in Kerala.
<br>
<br>Some light rain fell but the rest of Saturday was clear and the Kollam police’s raids across the district to check the tide of Child Sexual Abuse Material (CSAM) went off smoothly. The Kollam raids were part of a state-wide crackdown after police noted a surge in CSAM traffic on the Internet during the lockdown. Incorrectly termed child porn (porn implies consenting adults), CSAM refers to images and videos of a child being sexually abused, or in a sex act, or just in an indecent moment. 
<br>
<br>The Kollam police teams hit nine addresses. "Nine people had been tracked down for accessing and sharing child porn on [the] Telegram app,” a Kollam City Cyber Cell officer said. 
<br>
<br>By evening, the Kollam police had picked up nine suspects and taken them to the local police stations for questioning. The various devices seized from the suspects – ranging from mobile phones to laptops and pen drives – were sent for forensic analysis. By the end of the day, the police had registered cases under the Protection of Children from Sexual Offences (POCSO) Act and the Information Technology (IT) Act against all nine, all men under the age of 25. 
<br>
<br>For Kerala police, which has the oldest and most visible operation in India against CSAM, the Kollam operation was the largest in that day’s crackdown, codenamed P-HUNT 20.1. The 'P', ostensibly, stood for paedophiles; and the 20.1 for the first operation of the year 2020. Version 1 of the P-HUNT, the first dedicated operation by any Indian police force against CSAM, was organised in 2017. 
<br>
<br>In October 2019, the police had picked up 38 people from 21 places across 11 districts. In April 2019, it had arrested 21 people in a similar raid across 12 districts. This year, in the first week of June, following a tipoff from UNICEF, the United Nations body for children, the police had arrested three people who were members of a WhatsApp group that circulated CSAM. 
<br>
<br>For the June 27 raid, the net was cast wider – Kerala Police formed 117 teams across the state, registered 89 cases and arrested 47 suspects. Not all offenders could be traced or arrested that day. For evidence, it had seized 143 devices including laptops, mobile phones, modems, hard disks, memory cards, and computers. 
<br>"(State Police) Headquarters tightly co-ordinates these raids. They pass on a list of names, addresses, and phone numbers to the district headquarters. And then a date is fixed so that we raid the suspects simultaneously across the state”, ,” says a police officer who took part in the operation. Simultaneous raids are important as the Police try and arrest all the members of a particular WhatsApp or Telegram group, he adds. “Otherwise, members will get tipped off and abscond if we do it one by one”. 
<br>
<br>The raids were based on information from the Counter Child Sexual Exploitation Centre (CCSEC) , India’s first dedicated unit to prevent child sexual exploitation via the Internet, set up in 2019 by Kerala Police. 
<br>The CCSEC works closely with Interpol, the international criminal police organisation based in France, to collect information on CSAM usage across Kerala. An officer with CCSEC told FactorDaily that Kerala Police has been given access to a portal — the Internet Crimes Against Children and Child Online Protective Services (ICACCOPS) — that allows it to see reports of CSAM usage in Kerala, along with the user’s IP address, date and time of access, the URL of the content, as well as the actual content. “Every few months, we collate all the incidents whose IP addresses are from Kerala. We segregate the information by district, pass it on to district headquarters, and plan a simultaneous raid”. 
<br>
<br>The International Centre for Missing &amp; Exploited Children (ICMEC), a privately-funded NGO that works with law enforcement agencies, the UN and Interpol, has shown selected officers of Kerala Police how to use special technology tools to track and investigate CSAM.</p>
                        
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

<section class="content15 cid-sg7UbcSvCo" id="content15-q">

    

    
    <div class="container">
        <div class="row justify-content-center">
            <div class="card col-md-12 col-lg-8">
                <div class="card-wrapper">
                    <div class="card-box align-left">
                        
                        <p class="mbr-text mbr-fonts-style display-7">"(State Police) Headquarters tightly co-ordinates these raids. They pass on a list of names, addresses, and phone numbers to the district headquarters. And then a date is fixed so that we raid the suspects simultaneously across the state”, ,” says a police officer who took part in the operation. Simultaneous raids are important as the Police try and arrest all the members of a particular WhatsApp or Telegram group, he adds. “Otherwise, members will get tipped off and abscond if we do it one by one,” says Manoj Abraham, XXXX</p>
                        
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

<section class="content15 cid-sg89dns1OD" id="content15-s">

    

    
    <div class="container">
        <div class="row justify-content-center">
            <div class="card col-md-12 col-lg-8">
                <div class="card-wrapper">
                    <div class="card-box align-left">
                        
                        <p class="mbr-text mbr-fonts-style display-7">After the Union government imposed the COVID-19 lockdown in end-March 2020, Kerala police began to monitor 11 social media websites including WhatsApp, Facebook, Instagram, TikTok and Telegram. But the focus was on two platforms — WhatsApp and Telegram. Some of these groups — named Sreyayude, Thavalam, Manthanga Girl and Thanasertha — had over 200 members each.
<br>
<br>The arrests revealed how consumption of CSAM spanned the spectrum of society. In Idukki, it was a doctor in his early 30s working at a primary health centre, while in Kottayam, it was a hotel management graduate working in West Asia who got stuck in India when he came home and the government announced a sudden lockdown. In Kannur, it was a man in his late 30s who had done a short stint in the Indian Navy and then taken up a job in Abu Dhabi. He had come to Kerala recently.
<br>
<br>According to the police, many of those arrested were men in their early 20s. In Kollam, everyone arrested was below 25 years old, including a 16-year-old, a minor. In the case of the minor, police officers have said that they will consult mental health experts and send the minor for counselling.
<br>According to the CCSEC officer, some people had sold CSAM for small amounts of money. “In about three or four cases, the persons involved provided CSAM content in return for money. The sums involved were typically between Rs 25 and Rs 50 and transacted over PayTM or UPI,” he said.</p>
                        
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

<section class="image3 cid-sg8bk4HVzN" id="image3-t">
    

    

    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-8">
                <div class="image-wrapper">
                    <img src="assets/images/kerala-arrest-map-740x597.png" alt="Mobirise">
                    
                </div>
            </div>
        </div>
    </div>
</section>

<section class="content15 cid-sg8eoTRnen" id="content15-v">

    

    
    <div class="container">
        <div class="row justify-content-center">
            <div class="card col-md-12 col-lg-8">
                <div class="card-wrapper">
                    <div class="card-box align-left">
                        <h4 class="card-title mbr-fonts-style mbr-white mb-3 display-5"><strong>INDIA AND CSAM</strong></h4>
                        <p class="mbr-text mbr-fonts-style display-7">An idea of how much CSAM has flooded Indian cyberspace can be gathered from a 2019 report by the US-based National Center for Missing and Exploited Children (NCMEC). The Center runs a CyberTipline on which US federal law requires companies such as Facebook, Twitter and Apple to report instances of CSAM on their platforms. Over 1,400 companies have registered with the Cyber Tipline, and their reports are geotagged.
<br>In 2019, the NCMEC got 16.9 million suspected CSAM reports, of which nearly 1.98 million were from India — the single-largest out of 245 countries. The Indian subcontinent ranks high when it comes to CSAM consumption. Pakistan comes second to India with 1.15 million reports and Bangladesh generated more than half a million reports of CSAM consumption.</p>
                        
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

<section class="image3 cid-sg9CnnTfAA" id="image3-1i">
    

    

    <div class="container-fluid">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-12">
                <div class="image-wrapper">
                    <img src="assets/images/world-map-1400x845.png" alt="Mobirise">
                    
                </div>
            </div>
        </div>
    </div>
</section>

<section class="content15 cid-sg8gAFuCHo" id="content15-x">

    

    
    <div class="container">
        <div class="row justify-content-center">
            <div class="card col-md-12 col-lg-8">
                <div class="card-wrapper">
                    <div class="card-box align-left">
                        
                        <p class="mbr-text mbr-fonts-style display-7">As far as companies go, Facebook (which includes WhatsApp and Instagram) sent 93 per cent of the tips (15.8 million out of 16.9 million reports worldwide). Google nearly 450,000 and Microsoft 123,000. Snapchat reported 82,000 cases and Twitter 45,000.</p>
                        
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

<section class="header10 cid-sg8m1Zhvdv" id="header10-y">

    

    

    <div class="align-center container-fluid">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9">
                <h1 class="mbr-section-title mbr-fonts-style mb-3 display-5"><strong>ELECTRONIC SERVICE PROVIDERS WITH </strong><br><strong>MORE THAN 1,000 CSAM REPORTS</strong></h1>
                
                
                <div class="image-wrap mt-4">
                    <img src="assets/images/data-1000x1000.png" alt="Mobirise" title="">
                </div>
            </div>
        </div>
    </div>
</section>

<section class="content15 cid-sg8ngLcvjA" id="content15-z">

    

    
    <div class="container">
        <div class="row justify-content-center">
            <div class="card col-md-12 col-lg-8">
                <div class="card-wrapper">
                    <div class="card-box align-left">
                        
                        <p class="mbr-text mbr-fonts-style display-7">There are several caveats. For one, the use of proxies and anonymizers distorts and undercounts the numbers in many countries. The NCMEC report also notes that 1.6 million reports have no country listed for reasons such as no IP addresses or proxy IPs.
<br>Then, reports by companies also depend on their infrastructure for detecting CSAM. Facebook has invested considerably in CSAM detection, which is why it accounts for more than 90 per cent of CSAM reports. At the other end, while websites such as 4chan and 8chan have a long history of easy availability of CSAM, they have reported very few cases to NCMEC.</p>
                        
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

<section class="header10 cid-sg8tMs9qCu" id="header10-12">

    

    

    <div class="align-center container-fluid">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9">
                <h1 class="mbr-section-title mbr-fonts-style mb-3 display-5"><strong>History of CSAM Prosecution in India</strong></h1>
                
                
                <div class="image-wrap mt-4">
                    <img src="assets/images/frame-2-1114x1556.png" alt="Mobirise" title="">
                </div>
            </div>
        </div>
    </div>
</section>

<section class="content15 cid-sg8vWTh9Px" id="content15-13">

    

    
    <div class="container">
        <div class="row justify-content-center">
            <div class="card col-md-12 col-lg-8">
                <div class="card-wrapper">
                    <div class="card-box align-left">
                        
                        <p class="mbr-text mbr-fonts-style display-7">India's laws against CSAM are comprehensive, says A Nagarathna, a legal scholar who heads the Advanced Centre on Research, Development and Training in Cyber Laws and Forensics at the National Law School of India University, Bengaluru.
<br>“But the implementation is completely lacking,” she says.
<br>The numbers back her. The NCMEC recorded nearly 2 million instances of access to CSAM from India in 2019 alone. But the National Crime Records Bureau’s data show that we are prosecuting a tiny fraction of this.
<br>Consider the IT Act, which prosecutes publishing of CSAM under Section 67(B). NCRB started collecting data on cybercrime since 2014 and has data on prosecuting CSAM from 2014 till 2019.
<br>Only five and eight cases were filed in 2014 and 2015 respectively under Section 67(B). Since then, numbers have increased— 17 cases were filed in 2016, 46 in 2017, and 82 in 2018. In 2019, 102 cases were registered under Section 67(B), with Kerala(27) and Uttar Pradesh(25) accounting for half of these cases.</p>
                        
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

<section class="slider2 cid-sg8w68pUup" id="slider2-14">
    

    
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-md-6">
                <div class="carousel slide carousel-fade" id="sg9DSz2q92" data-interval="5000">
                    
                    <ol class="carousel-indicators">
                        <li data-slide-to="0" class="active" data-target="#sg9DSz2q92"></li>
                        <li data-slide-to="1" data-target="#sg9DSz2q92"></li>
                        <li data-slide-to="2" data-target="#sg9DSz2q92"></li><li data-slide-to="3" data-target="#sg9DSz2q92"></li>
                    </ol>
                    <div class="carousel-inner">
                        
                        <div class="carousel-item slider-image item active">
                            <div class="item-wrapper">
                                <img class="d-block w-100" src="assets/images/case1-462x462.png" data-slide-to="1">
                                
                            </div>
                        </div>
                        <div class="carousel-item slider-image item">
                            <div class="item-wrapper">
                                <img class="d-block w-100" src="assets/images/case2-546x546.png" data-slide-to="2">
                                
                            </div>
                        </div><div class="carousel-item slider-image item">
                            <div class="item-wrapper">
                                <img class="d-block w-100" src="assets/images/case3-462x462.png" data-slide-to="0">
                                
                            </div>
                        </div><div class="carousel-item slider-image item">
                            <div class="item-wrapper">
                                <img class="d-block w-100" src="assets/images/case4-462x462.png" data-slide-to="0">
                                
                            </div>
                        </div>
                    </div>
                    <a class="carousel-control carousel-control-prev" role="button" data-slide="prev" href="#sg9DSz2q92">
                        <span class="mobi-mbri mobi-mbri-arrow-prev" aria-hidden="true"></span>
                        <span class="sr-only">Previous</span>
                    </a>
                    <a class="carousel-control carousel-control-next" role="button" data-slide="next" href="#sg9DSz2q92">
                        <span class="mobi-mbri mobi-mbri-arrow-next" aria-hidden="true"></span>
                        <span class="sr-only">Next</span>
                    </a>
                </div>
            </div>
        </div>
    </div>
</section>

<section class="content15 cid-sg8xTD54Lq" id="content15-15">

    

    
    <div class="container">
        <div class="row justify-content-center">
            <div class="card col-md-12 col-lg-8">
                <div class="card-wrapper">
                    <div class="card-box align-left">
                        
                        <p class="mbr-text mbr-fonts-style display-7">More shockingly, the police in the 19 metropolitan cities filed only 15 of these cases in the four years between 2016 and 2019. Delhi accounts for six of these, while Bengaluru, Chennai, and Mumbai have filed two cases. each.<br><br>Police have filed charge sheets for 120 of the 260 cases across India between 2014 and 2019, a follow-up rate of 46 pc. But at the courts, CSAM convictions turn into a trickle.
<br><br>In the six years between 2014 and 2019, trials were completed in only eight cases: Six people have been convicted in these cases. By the end of 2019, the courts had a pendency percentage of 98.8 pc for cases filed under the IT Act to prosecute CSAM.
<br><br>The POCSO Act has seen more prosecutions than the IT Act —between 2014 and 2019, 2481 cases have been filed under Section 14 and Section 15 of the Act.
<br><br>In particular, the last few years have seen a significant drive to register more cases, with 374 cases in 2017 812 cases in 2018, and 1114 cases in 2019. Odisha leads in registered cases with 885 cases, followed by Bihar (368), Rajasthan, Kerala, and Jharkhand.
<br><br>But, just as in IT cases, our biggest cities have seen very few prosecutions. Of the 2,347 cases filed from 2016-2019, only 87 of these were filed in the largest 19 metros. Jaipur alone accounts for more than half with 27 cases. Hyderabad filed no cases in these four years, while Delhi, Mumbai, Kolkata, Chennai,and Bangalore filed 42 cases altogether.</p>
                        
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

<section class="image3 cid-sg8zFFkOhr" id="image3-18">
    

    

    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-10">
                <div class="image-wrapper">
                    <img src="assets/images/frame-7-1-1099x988.png" alt="Mobirise">
                    
                </div>
            </div>
        </div>
    </div>
</section>

<section class="content15 cid-sg8zZDLaft" id="content15-19">

    

    
    <div class="container">
        <div class="row justify-content-center">
            <div class="card col-md-12 col-lg-8">
                <div class="card-wrapper">
                    <div class="card-box align-left">
                        
                        <p class="mbr-text mbr-fonts-style display-7">Once POSCO cases are registered, the police have largely been prompt in filing charge sheets. Between 2014 and 2019, over 80 per cent of FIRs were converted into charge sheets.
<br><br>But it is at the courts where prosecution gets stuck. Between 2014 and 2019, out of 1,777 cases that were pending trial, only 295 cases could be decided: 129 cases resulted in convictions while 164 resulted in acquittals.
<br><br>The NCRB data on trafficking also classifies cases where children have been trafficked under the head of “Child pornography”. Between 2016 and 2019, 316 such cases have been recorded in Karnataka, Kerala, Madhya Pradesh, and Rajasthan.
<br><br>"Whether it is the POCSO or IT Act, cases registered are quite low," the NLSIU’s Nagarathna says.
<br><br>There are many reasons behind this — reluctance to register cases, cases not being reported and so on. "When it comes to any cybercrime including this, we hardly have any police officers who take it seriously. Unfortunately, for child sexual abuse, they should be more proactive. But it remains the same," she says.
<br><br>According to Nagarathna, police officers need training in handling digital evidence. "We have done a lot of sensitisation programmes for Special Juvenile Police units on sexual offences. But this training does not cover online sexual offenses," she says.</p>
                        
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

<section class="content5 cid-sg8B7tMFqN" id="content5-1a">
    
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-7">
                
                <h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5"><strong>THE TIPPING POINT:
</strong><div><strong>CSAM PROSECUTION GETS A BOOST</strong></div></h4>
                <p class="mbr-text mbr-fonts-style display-7">This mismatch between CSAM consumption and prosecution in India would change only in 2018 with the introduction of a bill in the United States.
<br><br>In the US, the NCMEC runs CyberTipline, is a centralised mechanism that the public as well as electronic service providers (ESP) such as Facebook and Google can use to report CSAM. The ESPs account for nearly 99 per cent of the reports. The NCMEC reviews each tip and then forwards it to US law enforcement agencies for investigation.
<br><br>On 12 December 2018, President Trump signed into law the CyberTipline Modernization Act of 2018, which allowed the CyberTipline to forward tips to foreign law enforcement agencies approved by the US government. Importantly, foreign law enforcement agencies would have access to tips on CSAM from companies based in the US.
<br><br>In India, matters moved rapidly. By February 2019, the Union Cabinet approved access to Tipline reports from NCMEC to prosecute offenders. On 26 April 2019, a little over four months since the law was passed in the US, the NCMEC signed an agreement with the NCRB, giving the Indian agency access to CyberTipline reports.<br>
<br>The NCRB would also be able to share these reports with law enforcement agencies across India. Access to the Tiplines comes with a few restrictions —the tipline has to be accessed on a standalone computer through a VPN, and tipline reports cannot be shared with anyone other than law enforcement agencies.</p>
            </div>
        </div>
    </div>
</section>

<section class="image3 cid-sg8Hc8OvH9" id="image3-1b">
    

    

    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-8">
                <div class="image-wrapper">
                    <img src="assets/images/frame-28-740x540.jpg" alt="Mobirise">
                    
                </div>
            </div>
        </div>
    </div>
</section>

<section class="content15 cid-sg8HrhYHhg" id="content15-1c">

    

    
    <div class="container">
        <div class="row justify-content-center">
            <div class="card col-md-12 col-lg-8">
                <div class="card-wrapper">
                    <div class="card-box align-left">
                        
                        <p class="mbr-text mbr-fonts-style display-7">This NCMEC deal helped Indian police departments enforce the IT Act. One of the reasons that only a handful of cases under the IT Act have been recorded is that the Indian government has no jurisdiction over the servers run outside India by companies such as Facebook, Google, Twitter, and Telegram. With the NCMEC deal, the government has found a way to circumvent this when it comes to CSAM content. Now, ESPs like Facebook, Google, and Microsoft report to NCMEC, and they in turn forward these reports to NCRB.
<br><br>The Indian government has also beefed up the laws to prosecute CSAM. In July 2019, Parliament passed an amendment to the POCSO Act which, among other things, promises more stringent punishments on CSAM. For using children for pornographic purposes, jail was set to a minimum of five years. This could go up to life imprisonment or death if aggravated penetrative sexual assault had happened.
<br><br>The amendment also increased the punishment for storage of pornographic material to five years. It included two offences. One, failing to to destroy, delete, or report CSAM. Two, transmitting, displaying, and distributing such material. In March 2020, the government notified the updated POCSO Rules 2020, making these new amendments effective from March 9.
<br><br>The sum of these actions has been an unprecedented surge in prosecutions across the country. By March 2020, the NCRB had shared 32,719 NCMEC CyberTipline Reports. The NCRB says more than 182 FIRs have been filed (many states have not yet set up the specialised units, and those that have done so are yet to get going).</p>
                        
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

<section class="slider1 cid-sg8QA358qN mbr-fullscreen" id="slider1-1d">
    
    <div class="carousel slide carousel-fade" id="sg9DSFw7jB" data-interval="5000">
        <ol class="carousel-indicators">
            <li data-slide-to="0" class="active" data-target="#sg9DSFw7jB"></li>
            <li data-slide-to="1" data-target="#sg9DSFw7jB"></li>
            <li data-slide-to="2" data-target="#sg9DSFw7jB"></li><li data-slide-to="3" data-target="#sg9DSFw7jB"></li><li data-slide-to="4" data-target="#sg9DSFw7jB"></li><li data-slide-to="5" data-target="#sg9DSFw7jB"></li>
        </ol>
        <div class="carousel-inner">
            <div class="carousel-item slider-image item active">
                <div class="item-wrapper">
                    <img class="d-block w-100" src="assets/images/m1-1440x738.jpg">
                    
                    
                </div>
            </div>
            <div class="carousel-item slider-image item">
                <div class="item-wrapper">
                    <img class="d-block w-100" src="assets/images/m2-1440x738.jpg">
                    
                    
                </div>
            </div>
            <div class="carousel-item slider-image item">
                <div class="item-wrapper">
                    <img class="d-block w-100" src="assets/images/m3-1440x738.jpg">
                    
                    
                </div>
            </div><div class="carousel-item slider-image item">
                <div class="item-wrapper">
                    <img class="d-block w-100" src="assets/images/m4-1440x738.jpg">
                    
                    
                </div>
            </div><div class="carousel-item slider-image item">
                <div class="item-wrapper">
                    <img class="d-block w-100" src="assets/images/m5-1440x738.jpg">
                    
                    
                </div>
            </div><div class="carousel-item slider-image item">
                <div class="item-wrapper">
                    <img class="d-block w-100" src="assets/images/m6-1440x738.jpg">
                    
                    
                </div>
            </div>
        </div>
        <a class="carousel-control carousel-control-prev" role="button" data-slide="prev" href="#sg9DSFw7jB">
            <span class="mobi-mbri mobi-mbri-arrow-prev" aria-hidden="true"></span>
            <span class="sr-only">Previous</span>
        </a>
        <a class="carousel-control carousel-control-next" role="button" data-slide="next" href="#sg9DSFw7jB">
            <span class="mobi-mbri mobi-mbri-arrow-next" aria-hidden="true"></span>
            <span class="sr-only">Next</span>
        </a>
    </div>
</section>

<section class="content5 cid-sg8RhwDCOI" id="content5-1e">
    
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-7">
                
                
                <p class="mbr-text mbr-fonts-style display-7">Even the CBI has got into the act. It has set up a special unit — the Online Child Sexual Abuse and Exploitation Prevention/ Investigation (OCSAE) unit — to investigate CSAM.
<br>In October 2019, based on a tipoff from the German Embassy, the CBI booked cases against seven people in Delhi, Tamil Nadu, Haryana, West Bengal, Rajasthan and Uttar Pradesh. These arrests were based on the conviction in Germany of Sascha Treppke who was a member of 29 WhatsApp groups that shared CSAM. Seven people from India were also members of these groups. The OCSAE unit also booked a Delhi-based firm for hosting websites with CSAM content on servers based in Russia.</p>
            </div>
        </div>
    </div>
</section>

<section class="content15 cid-sg8RAvu8J7" id="content15-1f">

    

    
    <div class="container">
        <div class="row justify-content-center">
            <div class="card col-md-12 col-lg-8">
                <div class="card-wrapper">
                    <div class="card-box align-left">
                        <h4 class="card-title mbr-fonts-style mbr-white mb-3 display-5"><strong>THE TIPPING POINT:
</strong><div><strong>CSAM PROSECUTION GETS A BOOST</strong></div></h4>
                        <p class="mbr-text mbr-fonts-style display-7">In the first week of October 2020,the Kerala Police completed Operation P-Hunt 20.2, the second simultaneous raid across the state for prosecuting CSAM. This raid saw 41 persons arrested for accessing CSAM on WhatsApp and Telegram. A press release from the Kerala Police stated “There is still heightened online activity seen from Kerala by those seeking child abuse material on the net, and particularly the dark net,”Cases rise but some take years to file While there has been improvement in filing cases, there is still a question mark on successful conviction, given the poor record of the courts. Long delays in filing charge sheets are common as a result of long turnaround times for analysing phones by Forensic Science Laboratories (FSL) . Additionally, difficulty in obtaining information from servers located outside India has led to poor conviction rates in cases under the IT Act.
<br>One reason is that confiscation of digital evidence continues to be a challenge for investigating agencies. "We are talking about evidence from computers, mobile phones, servers, and ISPs. Often the content is uploaded on platforms like Google or Facebook who are not based in India," she says.
<br>Under The Code of Criminal Procedure, the Investigating Officer has to write to a local magistrate, who, in turn, forwards the request to the Central Bureau of Investigation (CBI). The CBI scrutinizes the application. A lot of cases are rejected at the vetting stage. If it makes through this stage, it is marked to the ministries of External Affairs and Home Affairs. The Ministries then forward it to the diplomats of the country where the server is located. Once the request reaches the host country, it has to be processed through a similar stack in reverse: justice department, a local magistrate, local police, and then the company that hosts the server.
<br>"Cracking a case during investigation is different from getting a successful conviction during prosecution." The evidence in such cases are often intangible, or very technical. "Requiring the same burden of proof in a child sexual abuse case, compared to that of a conventional crime, makes it difficult," she says.
<br>At the same time, Nagarathna says, we need to focus as much on blocking content as on prosecution. "We are trying to focus more on finding the offender and punishing the offender. But the offending content continues to live in cyberspace," she says. "That adds more to psychological trauma of the victim.” India needs an approach that focuses on immediately blocking the content, as well as prosecuting the offender.
<br>Take Kerala, which has been the most aggressive state in pursuing CSAM cases in India. In 2015, a Facebook page titled 'Kochu Sundarikal' (Little Beauties) was shut down: It featured normal pictures of young girls but had extreme sexual comments. Kerala police took four years to file a charge sheet as it had to gather information from Facebook, whose servers are outside their jurisdiction. It is yet to be seen if the new MoU speeds up collecting evidence for CSAM related crimes.
<br>The other big question is about the children --- the victims of CSAM. A large percentage of CSAM content flowing through social media is of South Asian origin. Yet, the government does not have any policy to deal with identifying the children featured in these photographs and videos.
<br>A related question is if this surge in online child abuse images can lead to actual physical sexual abuse of children. According to Tulir’s Vidya Reddy, there is a lot of evidence that points to this direction. " A lot of research has showed that there is a high correlation between people who view child sexual images and those who make physical contact with children", she says.
<br>US clinical psychologists Michael Bourke and Andres Hernandez made waves in 2009 with a study that showed how most CSAM offenders had also committed child sex offences physically. The study, which covered 155 men convicted of possessing child sexual images in North Carolina, found that 85 per cent admitted to having sexually molested a child at least once. On average, each offender had abused 13.5 victims.
<br>"There's a whole bunch of material out there which helps people rationalise that what they are interested is perfectly legitimate and normal," says Reddy. "It definitely gives impetus for a person to go out and abuse".
<br>“The bigger problems of missing children and child abuse that happens on the ground are more difficult to tackle,” said Rajput. None of these cases has been reported by victims so it’s difficult to identify or rescue the victim in these cases. This drive is aimed to deter the transmission of CSAM that happens through social media on digital devices, he said.</p>
                        
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

<section class="gallery3 cid-sg8RSGOkLG" id="gallery3-1g">
    
    
    <div class="container">
        
        <div class="row mt-4">
            <div class="item features-image сol-12 col-md-6 col-lg-4">
                <div class="item-wrapper">
                    <div class="item-img">
                        <img src="assets/images/p1-335x471.jpeg" alt="">
                    </div>
                    
                    
                </div>
            </div>
            <div class="item features-image сol-12 col-md-6 col-lg-4">
                <div class="item-wrapper">
                    <div class="item-img">
                        <img src="assets/images/p2-335x471.jpeg" alt="">
                    </div>
                    
                    
                </div>
            </div>
            <div class="item features-image сol-12 col-md-6 col-lg-4">
                <div class="item-wrapper">
                    <div class="item-img">
                        <img src="assets/images/p3-335x471.jpeg" alt="">
                    </div>
                    
                    
                </div>
            </div>
            
        </div>
    </div>
</section>

<section class="gallery3 cid-sg8URA76FZ" id="gallery3-1h">
    
    
    <div class="container">
        
        <div class="row mt-4">
            <div class="item features-image сol-12 col-md-6 col-lg-4">
                <div class="item-wrapper">
                    <div class="item-img">
                        <img src="assets/images/p4-335x471.jpeg" alt="">
                    </div>
                    
                    
                </div>
            </div>
            <div class="item features-image сol-12 col-md-6 col-lg-4">
                <div class="item-wrapper">
                    <div class="item-img">
                        <img src="assets/images/p5-335x471.jpeg" alt="">
                    </div>
                    
                    
                </div>
            </div>
            <div class="item features-image сol-12 col-md-6 col-lg-4">
                <div class="item-wrapper">
                    <div class="item-img">
                        <img src="assets/images/p4-335x471.jpeg" alt="">
                    </div>
                    
                    
                </div>
            </div>
            
        </div>
    </div>
</section><section style="background-color: #fff; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', 'Helvetica Neue', Arial, sans-serif; color:#aaa; font-size:12px; padding: 0; align-items: center; display: flex;"><a href="https://mobirise.site/d" style="flex: 1 1; height: 3rem; padding-left: 1rem;"></a><p style="flex: 0 0 auto; margin:0; padding-right:1rem;"></p></section><script src="assets/web/assets/jquery/jquery.min.js"></script>  <script src="assets/popper/popper.min.js"></script>  <script src="assets/tether/tether.min.js"></script>  <script src="assets/bootstrap/js/bootstrap.min.js"></script>  <script src="assets/smoothscroll/smooth-scroll.js"></script>  <script src="assets/theme/js/script.js"></script>  
  
  
</body>
</html>